{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COMP-4740 Final Project\n**Created by Saffa Alvi and Nour ElKott**\n\n## Objective\n> The purpose of this research data analysis project is to apply deep learning approaches to explore Computer Vision and create a model for the Dogs vs. Cats competition on Kaggle.com. [1] The objective is to use the Kaggle provided dataset and write an algorithm to classify whether the images in the dataset are of a dog or a cat. The goal of this project is to build a performative model to accurately predict the classes of the unlabeled images in the test dataset and to answer the research questions, defined in this report, that are related to computer vision and this competition topic. Our model accuracy will also be compared to other existing models and evaluated to see which properties/characteristics of our model affect its overall accuracy.\n> \n\n[1] https://www.kaggle.com/competitions/dogs-vs-cats","metadata":{}},{"cell_type":"markdown","source":"# Imports\nThe following libraries, functions, etc were imported to help with constructing the CNN model.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport pandas as pd\nimport imageio\nimport matplotlib.pyplot as plt\nimport os\nimport sklearn\nimport cv2\nimport zipfile","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-26T23:38:20.404196Z","iopub.execute_input":"2022-04-26T23:38:20.404501Z","iopub.status.idle":"2022-04-26T23:38:23.229873Z","shell.execute_reply.started":"2022-04-26T23:38:20.404449Z","shell.execute_reply":"2022-04-26T23:38:23.228870Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Define the datasets (Dogs vs. Cats from Kaggle)","metadata":{}},{"cell_type":"markdown","source":"**dogs-vs-cats/train.zip** The training dataset provided contains 25,000 images of dogs and cats. \n\n**dogs-vs-cats/test1.zip** Contains the images to test model on.\n\n*This notebook was created on Kaggle to help run the code faster so the dataset filepaths are different from those included in the raw source code and project submission folder*","metadata":{}},{"cell_type":"code","source":"# Extract zip files in dataset provided from Kaggle\nprint(os.listdir(\"../input\"))\nwith zipfile.ZipFile(\"../input/train.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"../input/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:38:23.234508Z","iopub.execute_input":"2022-04-26T23:38:23.242303Z","iopub.status.idle":"2022-04-26T23:38:40.118475Z","shell.execute_reply.started":"2022-04-26T23:38:23.242243Z","shell.execute_reply":"2022-04-26T23:38:40.117734Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Define Dataset paths (from Kaggle)","metadata":{}},{"cell_type":"code","source":"dataset_path = \"/kaggle/working/\"\ntrain_dataset = \"/kaggle/working/train\"\nfiles = os.listdir(train_dataset)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-04-26T23:38:40.121897Z","iopub.execute_input":"2022-04-26T23:38:40.122123Z","iopub.status.idle":"2022-04-26T23:38:40.142335Z","shell.execute_reply.started":"2022-04-26T23:38:40.122081Z","shell.execute_reply":"2022-04-26T23:38:40.141775Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Iterate through the files in the training data (dogs-vs-cats/train/) and save them into arrays\n\nThe train_x array will contain the image data, while the train_y array will contain the image label.\n\nImages from the training dataset are resized to 80x80 and read in greyscale.","metadata":{}},{"cell_type":"code","source":"# Training Dataset\ntrain_x = []\ntrain_y = []\n\n# Iterate through files in training dataset\nfor f in files:\n  # Get label/animal from filename - ex. cat.0.jpg, label is before .\n  label = f.split(\".\")[0]\n  filepath = train_dataset + \"/\" + f                  # image filepath\n  data = imageio.imread(filepath, as_gray = True)     # read the specified image (in greyscale)\n  data_arr = cv2.resize(data, dsize = (80, 80))       # resize the image to 80x80\n  # add image data and label to respective arrays\n  train_x.append(data_arr)\n  train_y.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:38:40.143631Z","iopub.execute_input":"2022-04-26T23:38:40.144134Z","iopub.status.idle":"2022-04-26T23:39:49.362758Z","shell.execute_reply.started":"2022-04-26T23:38:40.143868Z","shell.execute_reply":"2022-04-26T23:39:49.362015Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Training Data\nprint(len(train_x))\nprint(len(train_y))","metadata":{"_uuid":"cfa2a50c1ea569d97806510e0e313e1ce9d7452b","execution":{"iopub.status.busy":"2022-04-26T23:39:49.364105Z","iopub.execute_input":"2022-04-26T23:39:49.364394Z","iopub.status.idle":"2022-04-26T23:39:49.370442Z","shell.execute_reply.started":"2022-04-26T23:39:49.364330Z","shell.execute_reply":"2022-04-26T23:39:49.369474Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Normalize/Scale Data and Change Dimensions\n\nNormalize the values in the training data so they are between 0 and 1. \n\nReshape the data as keras needs 4D datasets, and data was 3D.","metadata":{}},{"cell_type":"code","source":"X_train = tf.keras.utils.normalize(train_x, axis=1) \nX_train = np.expand_dims(X_train, axis=-1)\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:39:49.371990Z","iopub.execute_input":"2022-04-26T23:39:49.372608Z","iopub.status.idle":"2022-04-26T23:39:51.230447Z","shell.execute_reply.started":"2022-04-26T23:39:49.372561Z","shell.execute_reply":"2022-04-26T23:39:51.228555Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Label Encoding (Emotions -> Numbers)\n\nNeed to change the string values of animals (cat or dog) into numbers so the CNN can properly predict them based on classes/labels.","metadata":{}},{"cell_type":"code","source":"from keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder\n\nlb = LabelEncoder()\nY_train = lb.fit_transform(train_y)\nY_train","metadata":{"_uuid":"6e30159db4207451532ac085e617bc2669c93714","execution":{"iopub.status.busy":"2022-04-26T23:39:51.234309Z","iopub.execute_input":"2022-04-26T23:39:51.236387Z","iopub.status.idle":"2022-04-26T23:39:51.821302Z","shell.execute_reply.started":"2022-04-26T23:39:51.236314Z","shell.execute_reply":"2022-04-26T23:39:51.820451Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Building the Model\n\n2D Convolutional Neural Network (CNN) consisting of Conv2D, pooling, dropout regularization, flatten, and dense layers.\n\nRelu and Sigmoid are used as the activation functions. Sigmois is used since we want a prediction between 0 and 1 (0 = cat, 1 = dog)\n\nAdam is used as the optimizer and the loss function is binary crossentropy.","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras as keras\n\n# build the model\nmodel = keras.Sequential()\n\n# add the layers\n\n# hidden layers\nmodel.add(keras.layers.Conv2D(128, 3, input_shape=(80, 80, 1), activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((2,2)))\ntf.keras.layers.Dropout(0.30)\n\nmodel.add(keras.layers.Conv2D(256, 3, activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((2,2)))\ntf.keras.layers.Dropout(0.40)\n\nmodel.add(keras.layers.Flatten())\n\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:39:51.822492Z","iopub.execute_input":"2022-04-26T23:39:51.822747Z","iopub.status.idle":"2022-04-26T23:39:52.037275Z","shell.execute_reply.started":"2022-04-26T23:39:51.822702Z","shell.execute_reply":"2022-04-26T23:39:52.036465Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Depending on machine processing power, fitting the model can take a while (when tested on Kaggle only took about 5 minutes, when tested on local machines, could take up to an hour at 5 mins per epoch)","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train, Y_train, epochs=10, validation_split=0.2, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:39:52.038452Z","iopub.execute_input":"2022-04-26T23:39:52.038715Z","iopub.status.idle":"2022-04-26T23:41:48.619100Z","shell.execute_reply.started":"2022-04-26T23:39:52.038671Z","shell.execute_reply":"2022-04-26T23:41:48.618364Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Save the model so it can be loaded and used for predictions later on ","metadata":{}},{"cell_type":"code","source":"# Save the model\nmodel.save('model.h5')\njson_model = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(json_model)\n\nprint(\"Saved model!\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:41:48.621687Z","iopub.execute_input":"2022-04-26T23:41:48.621974Z","iopub.status.idle":"2022-04-26T23:41:48.851098Z","shell.execute_reply.started":"2022-04-26T23:41:48.621922Z","shell.execute_reply":"2022-04-26T23:41:48.850330Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Display Model Statistics (Accuracy and Loss)","metadata":{}},{"cell_type":"code","source":"# Display model stats\n\n# Model Accuracy\nplt.title('CNN Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# Model Loss\nplt.title('CNN Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:41:48.852254Z","iopub.execute_input":"2022-04-26T23:41:48.852708Z","iopub.status.idle":"2022-04-26T23:41:49.232007Z","shell.execute_reply.started":"2022-04-26T23:41:48.852658Z","shell.execute_reply":"2022-04-26T23:41:49.231186Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Predict on Test Dataset using the Model","metadata":{}},{"cell_type":"markdown","source":"### Test Dataset Preparation\n\nSimilar to how we processed the training data, iterate through the files in dogs-vs-cats/test1, read the images, resize to 80x80, and add to a test array.","metadata":{}},{"cell_type":"code","source":"test_data = []\ntest_data_image = []\ntest_dataset = \"/kaggle/working/test1\"\nfiles = os.listdir(test_dataset)\n\nfor f in files:\n  id = f.split(\".\")[0]\n  filepath = test_dataset + \"/\" + f\n  data = imageio.imread(filepath, as_gray = True)     # read the specified image (in greyscale)\n  data_arr = cv2.resize(data, dsize = (80, 80))       # resize the image to 80x80\n  test_data_image.append(data_arr)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:41:49.233254Z","iopub.execute_input":"2022-04-26T23:41:49.233730Z","iopub.status.idle":"2022-04-26T23:42:22.783126Z","shell.execute_reply.started":"2022-04-26T23:41:49.233681Z","shell.execute_reply":"2022-04-26T23:42:22.782435Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Normalize/Scale Data and Change Dimensions\n\nNormalize the values in the testing data so they are between 0 and 1. \n\nReshape the data as keras needs 4D datasets, and data was 3D.","metadata":{}},{"cell_type":"code","source":"test_data = tf.keras.utils.normalize(test_data_image, axis=1) \n\n# need to reshape the data as keras needs 4D datasets, and ours are 3D right now\ntest_data = np.expand_dims(test_data, axis=-1)\n# new reshaped dataset\nprint(test_data.shape)\n\n# Get the label encoding so user can be given prediction as \"cat or dog\" instead of \"0 or 1\"\nlabels = list(lb.classes_)\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:42:22.784306Z","iopub.execute_input":"2022-04-26T23:42:22.784597Z","iopub.status.idle":"2022-04-26T23:42:23.661990Z","shell.execute_reply.started":"2022-04-26T23:42:22.784548Z","shell.execute_reply":"2022-04-26T23:42:23.661224Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Predict the test dataset from the model","metadata":{}},{"cell_type":"code","source":"predictions = model.predict(test_data)\nprint(predictions[:3])\n\n# to get as classes (since we used sigmoid, will have to round)\nclasses = []\nfor p in predictions:\n  classes.append(round(p[0]))\n\nclasses[:3]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:42:23.663287Z","iopub.execute_input":"2022-04-26T23:42:23.663805Z","iopub.status.idle":"2022-04-26T23:42:25.829904Z","shell.execute_reply.started":"2022-04-26T23:42:23.663753Z","shell.execute_reply":"2022-04-26T23:42:25.828440Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Show the Dog or Cat Image and Model Prediction (Sample)","metadata":{}},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\n\nsize = len(test_data_image)\n\nimage = random.randint(0, size)\nplt.imshow(test_data_image[image], cmap=\"gray\")\nplt.show()\n\nmodel_prediction = int(classes[image])\n\nprint(\"Model prediction - class:\", model_prediction, \"which is a\", labels[model_prediction])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:42:25.831154Z","iopub.execute_input":"2022-04-26T23:42:25.831629Z","iopub.status.idle":"2022-04-26T23:42:26.000624Z","shell.execute_reply.started":"2022-04-26T23:42:25.831573Z","shell.execute_reply":"2022-04-26T23:42:25.999899Z"},"trusted":true},"execution_count":16,"outputs":[]}]}